{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**unlike bert_tokenizer (using homemade embedding layer) will use bert as embedding layer**\n",
        "\n",
        "will not train the weight or the variables of bert"
      ],
      "metadata": {
        "id": "zz0FX8Sp7q3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 1 : Importing dependencies**"
      ],
      "metadata": {
        "id": "Mz2nN-gs8eRj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swk3TjuF6hwo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHSyzfUg9alc",
        "outputId": "cfe63d51-e932-48e1-f40f-637a84b32156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.1)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30534 sha256=c6f982a4686446dd092a7034d40f2c8fffde0f924e78505744df5aa7fe2bf8a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/a4/72/df07592cea3ae06b5e846f5e52262f8b16748e829ca354b7df\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19472 sha256=6efb6a614986309b518ab447e38263352b7f7beb1bff897054d1ffaccc666c73\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/f3/85/b8cf1d8bfe55dc2ece0f1fcd4e91d6f8fc7b59ff3fd75329e1\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7911 sha256=d8712f50ded3270a7853fff2665fd9751d81bc9dcb9221614d0e89a025693d39\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/26/e9/df16869ccbd4abf517f1ff3be9a2c7ee5c5980fc87eea04fb1\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqDAg1Fh9pFb",
        "outputId": "ca6a249d-fca4-4df9-88f5-f6b67316ce0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 2 : Data preprocessing**"
      ],
      "metadata": {
        "id": "xJxiK0QoBK3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading files**\n",
        "\n",
        "import files from personal Google drive"
      ],
      "metadata": {
        "id": "5QW3faZpBODj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Dcy3vSeJsuG0",
        "outputId": "80cce030-825d-41e0-8578-8e1d50101d60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
        "data = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/bert/train.csv\",\n",
        "    header = None,\n",
        "    names = cols,\n",
        "    engine = \"python\",\n",
        "    encoding = \"latin1\"\n",
        ")"
      ],
      "metadata": {
        "id": "cY7e2DN-jvuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop([\"id\", \"date\", \"query\", \"user\"],\n",
        "          axis = 1,\n",
        "          inplace = True)"
      ],
      "metadata": {
        "id": "TqUeNhzykk-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XBGRv9Gsk0Ai",
        "outputId": "6a72b621-f98d-4d27-ffc7-fc317d625481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ebda2d6-4932-42db-8116-441aee23e601\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ebda2d6-4932-42db-8116-441aee23e601')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ebda2d6-4932-42db-8116-441aee23e601 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ebda2d6-4932-42db-8116-441aee23e601');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "abMME9aLk9sv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "cleaning"
      ],
      "metadata": {
        "id": "BXx5JBOYlBg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweet(tweet):\n",
        "    # decode tweets included in the lxml format -> BeautifulSoup.get_text() : 유니코드 텍스트만 들어있는 문자열 반환\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "    # remove metions -> find all the @ signs followed by letters or numbers -> replace them into white space\n",
        "    # r is to indicate that i am writing a regex\n",
        "    # + means that they can be repeated as many times as needed\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "    # remove url links\n",
        "    # ? : s can or cannot be there -> search http and https//letter&numbers./\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "    # remove everything that is not letters, ., !, ?\n",
        "    # ^ means not\n",
        "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
        "    # get rid of the spaces that are repeated several times\n",
        "    tweet = re.sub(r\" +\", ' ', tweet)\n",
        "    return tweet"
      ],
      "metadata": {
        "id": "zlvo_CPnlDIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply claean to all the tweets\n",
        "data_clean = [clean_tweet(tweet) for tweet in data.text]"
      ],
      "metadata": {
        "id": "8BXhgLfuoANf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_labels = data.sentiment.values\n",
        "# make the label of 4 into 1 (labels are made up of 0 and 4)\n",
        "data_labels[data_labels == 4] = 1"
      ],
      "metadata": {
        "id": "H7_56rakoKAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization**\n",
        "\n",
        "need to create a BERT layer to have acces to meta data for the tokenizer (like vocab size)"
      ],
      "metadata": {
        "id": "YA6e_nkXoUnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "# get BERT model from the website\n",
        "# trainable = False : won't fine tune the weights of BERT\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable = False)\n",
        "# get the vocab file for BERT tokenizer\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "# lower casing the text file\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "# create tokenizer\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
      ],
      "metadata": {
        "id": "DKc-cJ7Jofhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize every sentences\n",
        "def encode_sentence(sent):\n",
        "    # [CLS] token : token that is used for classification \n",
        "    # [CLS] token will be given at the beginning of all sentences\n",
        "    # Can distinguish between single and consecutive sentences\n",
        "    # [SEP] token : Use at the end of a sentence to separate sentences\n",
        "    return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]"
      ],
      "metadata": {
        "id": "NxnikElSuJvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_inputs would be list of encoded sentences applied to a cleaned sentence\n",
        "data_inputs = [encode_sentence(sentence) for sentence in data_clean]"
      ],
      "metadata": {
        "id": "hoB9jJJWuTWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Creation**\n",
        "\n",
        "create padded batches (to pad sentences for each batch independently)\n",
        "\n",
        "add the minimum of padding tokens possible\n",
        "\n",
        "for that, we sort sentences by length, apply padded_batches and then shuffle"
      ],
      "metadata": {
        "id": "ux7xTzN8udFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT needs 3 inputs\n",
        "\n",
        "# 1. tokenized version of the sentence\n",
        "def get_ids(tokens):\n",
        "    return tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "# 2. list of mask : indicates to BERT where the values of the sentences are\n",
        "def get_mask(tokens):\n",
        "    return np.char.not_equal(tokens, \"[PAD]\").astype(int)\n",
        "\n",
        "# 3. sequence of 1s and 0s\n",
        "# 0 : indicate that we are currently in the first sentence -> correspond to the tokens of the first sentence\n",
        "# 1 : corresponds to the tokens of the second sentence\n",
        "def get_segments(tokens):\n",
        "    seg_ids = []\n",
        "    current_seg_id = 0\n",
        "    for tok in tokens:\n",
        "        seg_ids.append(current_seg_id)\n",
        "        if tok == \"[SEP]\":\n",
        "            current_seg_id = 1 - current_seg_id\n",
        "    return seg_ids"
      ],
      "metadata": {
        "id": "8UHzG1faaDbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create padded batches (so i can pad sentences for each batch independently)\n",
        "\n",
        "this way can add the minimum of padding tokens possible\n",
        "\n",
        "for that, can sort sentences by length, apply padded_batches and the shuffle"
      ],
      "metadata": {
        "id": "BgX4YCg7-0Ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of all sentences, corresponding label and the length of the sentence\n",
        "# to iterate over data_inputs while having accounts at 'i' so that we can have access to the corresponding label (data_labels[i])\n",
        "data_with_len = [[sent, data_labels[i], len(sent)]\n",
        "                 for i, sent in enumerate(data_inputs)]\n",
        "# shuffle data_with_len\n",
        "# shuffle because in the initial data file, inputs are sorted according to the label (sentiments)\n",
        "random.shuffle(data_with_len)\n",
        "\n",
        "# sort every sentences according to the length\n",
        "# x[2] is len(sent)\n",
        "data_with_len.sort(key = lambda x: x[2])\n",
        "# sent_lab : sentence label\n",
        "sorted_all = [([get_ids(sent_lab[0]),\n",
        "                get_mask(sent_lab[0]),\n",
        "                get_segments(sent_lab[0])],\n",
        "               sent_lab[1])\n",
        "            # only when the length of the sentence is more than 7\n",
        "            for sent_lab in data_with_len if sent_lab[2] > 7]"
      ],
      "metadata": {
        "id": "Yd4xjiAHu6wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentences don't have the same length -> call generator\n",
        "# different length of inputs but same length of output\n",
        "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
        "                                             output_types = (tf.int32, tf.int32))"
      ],
      "metadata": {
        "id": "v8gegK1QyDxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "# padded_batch : 입력데이터의 크기가 가변일 때 같은 크기로 읽을 수 있도록 변환해주는 함수\n",
        "# https://kyoungseop.tistory.com/entry/tensorflow-dataset-paddedbatch-%ED%95%A8%EC%88%98\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE, padded_shapes = ((3, None), ()), padding_values = (0, 0))"
      ],
      "metadata": {
        "id": "2y4vahl5yRJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ceil() : gets the smaller integer that is higher than the number we pass\n",
        "# len(sorted_all) is the number of inputs\n",
        "NB_BATCHES = math.ceil(len(sorted_all) / BATCH_SIZE)\n",
        "NB_BATCHES_TEST = NB_BATCHES // 10\n",
        "# shuffle <- all_batched is sorted from the shortest to longest\n",
        "all_batched.shuffle(NB_BATCHES)\n",
        "# create test and train datasets\n",
        "test_dataset = all_batched.take(NB_BATCHES_TEST)\n",
        "train_dataset = all_batched.take(NB_BATCHES_TEST)"
      ],
      "metadata": {
        "id": "AvU-FXNfyxDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 3 : Model Building**"
      ],
      "metadata": {
        "id": "b_wXCa-c-3Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_sent = [\"[CLS]\"] + tokenizer.tokenize(\"Roses are red.\") + [\"[SEP]\"]\n",
        "bert_layer([tf.expand_dims(tf.cast(get_ids(my_sent), tf.int32), 0),\n",
        "            tf.expand_dims(tf.cast(get_mask(my_sent), tf.int32), 0),\n",
        "            tf.expand_dims(tf.cast(get_segments(my_sent), tf.int32), 0)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io50IzHOd54l",
        "outputId": "e239ed8d-b636-4e46-90f0-0d55021b509c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
              " array([[-9.27935660e-01, -4.10335362e-01, -9.65754867e-01,\n",
              "          9.07317877e-01,  8.12913775e-01, -1.74174383e-01,\n",
              "          9.11234617e-01,  3.41952175e-01, -8.74521255e-01,\n",
              "         -9.99989271e-01, -7.78409779e-01,  9.69385147e-01,\n",
              "          9.86160517e-01,  6.36962950e-01,  9.48631287e-01,\n",
              "         -7.51193106e-01, -4.58339304e-01, -7.08104551e-01,\n",
              "          4.62098330e-01, -6.57927275e-01,  7.60414660e-01,\n",
              "          9.99994814e-01, -3.96860719e-01,  3.44166040e-01,\n",
              "          6.16488695e-01,  9.94400144e-01, -7.76633799e-01,\n",
              "          9.38316584e-01,  9.59452271e-01,  7.32879400e-01,\n",
              "         -6.93436861e-01,  2.93080509e-01, -9.93785441e-01,\n",
              "         -1.64551824e-01, -9.67019558e-01, -9.95549619e-01,\n",
              "          5.32935441e-01, -6.88061237e-01,  1.34714758e-02,\n",
              "          2.98194177e-02, -9.18356538e-01,  4.20526206e-01,\n",
              "          9.99989092e-01,  2.52676457e-01,  6.06235445e-01,\n",
              "         -3.50750148e-01, -1.00000000e+00,  4.97585416e-01,\n",
              "         -8.95187378e-01,  9.62560952e-01,  9.43730593e-01,\n",
              "          9.03285563e-01,  1.54699653e-01,  5.86143672e-01,\n",
              "          5.80860376e-01, -4.05052930e-01, -2.76641808e-02,\n",
              "          2.98045874e-01, -2.83075958e-01, -6.47424459e-01,\n",
              "         -6.51523709e-01,  5.43847322e-01, -9.56302106e-01,\n",
              "         -9.22750413e-01,  9.61462915e-01,  8.27475429e-01,\n",
              "         -3.50112528e-01, -4.06405658e-01, -8.74317810e-02,\n",
              "         -9.98740345e-02,  8.96688342e-01,  3.00931484e-01,\n",
              "         -1.51129171e-01, -8.52713645e-01,  8.09592366e-01,\n",
              "          4.00989234e-01, -6.61605835e-01,  1.00000000e+00,\n",
              "         -6.16246402e-01, -9.86407042e-01,  8.90942812e-01,\n",
              "          8.11157525e-01,  5.81394494e-01, -6.33873045e-01,\n",
              "          3.78197789e-01, -1.00000000e+00,  6.76351368e-01,\n",
              "         -2.30612606e-01, -9.92552578e-01,  3.85461181e-01,\n",
              "          6.57650709e-01, -2.90105700e-01,  4.46832120e-01,\n",
              "          6.28524065e-01, -5.58409095e-01, -6.65295064e-01,\n",
              "         -4.72272336e-01, -9.28039253e-01, -3.54472458e-01,\n",
              "         -6.19735956e-01,  1.24534965e-01, -3.48905593e-01,\n",
              "         -4.23184305e-01, -4.20834869e-01,  4.56588626e-01,\n",
              "         -6.14471018e-01, -5.15243351e-01,  5.01909792e-01,\n",
              "          4.29147214e-01,  7.59821951e-01,  4.37516510e-01,\n",
              "         -4.33598280e-01,  6.30961955e-01, -9.59743083e-01,\n",
              "          7.73877442e-01, -3.95738006e-01, -9.87354517e-01,\n",
              "         -6.73180103e-01, -9.92996395e-01,  7.77800262e-01,\n",
              "         -5.05856395e-01, -3.19991022e-01,  9.69388843e-01,\n",
              "         -3.51620138e-01,  3.79092038e-01, -2.21649483e-01,\n",
              "         -9.51505601e-01, -1.00000000e+00, -8.80426824e-01,\n",
              "         -8.34713042e-01, -2.77321488e-01, -4.70461220e-01,\n",
              "         -9.83711958e-01, -9.56730247e-01,  6.61120951e-01,\n",
              "          9.56025839e-01,  1.62189022e-01,  9.99961376e-01,\n",
              "         -5.11205971e-01,  9.59530532e-01, -5.58609784e-01,\n",
              "         -8.00221026e-01,  8.48543882e-01, -5.58320463e-01,\n",
              "          8.33738327e-01,  2.63149440e-01, -7.33846903e-01,\n",
              "          3.16189617e-01, -4.83306170e-01,  6.87450051e-01,\n",
              "         -7.94889808e-01, -3.81298214e-01, -8.71705949e-01,\n",
              "         -9.49488103e-01, -3.62460107e-01,  9.51175570e-01,\n",
              "         -7.62520552e-01, -9.61278081e-01, -1.53293669e-01,\n",
              "         -4.02463555e-01, -5.69815516e-01,  8.52475941e-01,\n",
              "          7.99817860e-01,  5.33586502e-01, -6.96546555e-01,\n",
              "          4.84272480e-01,  2.24440709e-01,  7.31195271e-01,\n",
              "         -8.18208158e-01, -3.58149260e-01,  5.32028496e-01,\n",
              "         -4.41676080e-01, -9.25720811e-01, -9.87607241e-01,\n",
              "         -5.07007778e-01,  5.31485617e-01,  9.93827045e-01,\n",
              "          7.66175270e-01,  4.12393153e-01,  8.83270144e-01,\n",
              "         -3.85666430e-01,  8.81850243e-01, -9.67345178e-01,\n",
              "          9.86407518e-01, -3.13535601e-01,  3.57363939e-01,\n",
              "         -6.57590330e-01,  2.70097375e-01, -8.59113038e-01,\n",
              "          2.32003778e-01,  8.62853050e-01, -9.03662264e-01,\n",
              "         -7.94610202e-01, -2.82699138e-01, -4.76583779e-01,\n",
              "         -5.01097381e-01, -8.80422354e-01,  5.45586228e-01,\n",
              "         -4.41977412e-01, -5.77728868e-01, -1.25810161e-01,\n",
              "          9.06032085e-01,  9.80562270e-01,  8.44253480e-01,\n",
              "          5.20119429e-01,  7.80579507e-01, -9.23414409e-01,\n",
              "         -5.87243676e-01,  2.34754562e-01,  2.97746867e-01,\n",
              "          3.54463816e-01,  9.96218681e-01, -8.01237524e-01,\n",
              "         -2.79998392e-01, -9.39948916e-01, -9.83751893e-01,\n",
              "          3.82994339e-02, -9.28821862e-01, -2.94137865e-01,\n",
              "         -7.00600922e-01,  7.67863870e-01, -3.51922125e-01,\n",
              "          6.57683969e-01,  5.54107130e-01, -9.90459263e-01,\n",
              "         -7.80434251e-01,  5.50272763e-01, -5.03932953e-01,\n",
              "          5.56852698e-01, -3.53224486e-01,  7.86349773e-01,\n",
              "          9.69607055e-01, -6.54102147e-01,  7.34233081e-01,\n",
              "          8.81996632e-01, -9.14772093e-01, -7.82534719e-01,\n",
              "          8.52741301e-01, -4.38667715e-01,  8.24172378e-01,\n",
              "         -7.77354538e-01,  9.91627038e-01,  9.48048532e-01,\n",
              "          7.74401784e-01, -9.52811956e-01, -7.52400279e-01,\n",
              "         -8.65391254e-01, -8.10665190e-01, -1.91085368e-01,\n",
              "          6.22544922e-02,  9.39342737e-01,  6.60154998e-01,\n",
              "          5.10393083e-01,  3.03855330e-01, -7.58786082e-01,\n",
              "          9.97947276e-01, -8.39390576e-01, -9.73821759e-01,\n",
              "         -6.96807921e-01, -4.71226037e-01, -9.92139935e-01,\n",
              "          9.27336872e-01,  3.11118245e-01,  6.17148399e-01,\n",
              "         -5.93245387e-01, -7.30744183e-01, -9.74081159e-01,\n",
              "          9.14184034e-01,  2.35107005e-01,  9.90232766e-01,\n",
              "         -4.98075664e-01, -9.59739506e-01, -7.62371123e-01,\n",
              "         -9.30913389e-01, -4.32068184e-02, -2.13116318e-01,\n",
              "         -6.06085062e-01, -2.81608105e-02, -9.69718456e-01,\n",
              "          6.36244178e-01,  6.35316432e-01,  5.37905633e-01,\n",
              "         -8.91036153e-01,  9.99303102e-01,  1.00000000e+00,\n",
              "          9.73003805e-01,  9.01396930e-01,  8.87466669e-01,\n",
              "         -9.99958754e-01, -6.90021932e-01,  9.99997914e-01,\n",
              "         -9.93730485e-01, -1.00000000e+00, -9.37510908e-01,\n",
              "         -8.12253177e-01,  2.70661235e-01, -1.00000000e+00,\n",
              "         -2.87079006e-01, -1.50920168e-01, -9.31140304e-01,\n",
              "          8.18554997e-01,  9.78329062e-01,  9.94965553e-01,\n",
              "         -1.00000000e+00,  8.81453693e-01,  9.30843115e-01,\n",
              "         -7.06026793e-01,  9.76767123e-01, -6.08330071e-01,\n",
              "          9.75543499e-01,  5.93019545e-01,  5.54319203e-01,\n",
              "         -2.44307265e-01,  4.22843665e-01, -9.68066275e-01,\n",
              "         -9.14158463e-01, -7.75702596e-01, -7.79753447e-01,\n",
              "          9.98873472e-01,  2.67525733e-01, -7.70681024e-01,\n",
              "         -9.30970371e-01,  6.98258102e-01, -1.79436088e-01,\n",
              "          1.48644611e-01, -9.69404280e-01, -3.27199757e-01,\n",
              "          7.69222617e-01,  8.38437378e-01,  2.74363279e-01,\n",
              "          4.46673632e-01, -6.88233972e-01,  4.38525319e-01,\n",
              "         -6.96207285e-02,  2.83885568e-01,  6.96684837e-01,\n",
              "         -9.55272734e-01, -5.49684525e-01, -3.89561355e-01,\n",
              "          3.75222474e-01, -7.64761984e-01, -9.54122961e-01,\n",
              "          9.69721258e-01, -4.86066759e-01,  9.72205639e-01,\n",
              "          1.00000000e+00,  7.64813423e-01, -9.13303673e-01,\n",
              "          6.57082558e-01,  4.31852072e-01, -7.01079190e-01,\n",
              "          1.00000000e+00,  8.67337048e-01, -9.83669579e-01,\n",
              "         -5.84471703e-01,  7.79540896e-01, -6.77890062e-01,\n",
              "         -7.74523914e-01,  9.99660969e-01, -3.41093123e-01,\n",
              "         -8.14479649e-01, -6.48069143e-01,  9.86273110e-01,\n",
              "         -9.94089186e-01,  9.97643054e-01, -8.94537747e-01,\n",
              "         -9.79997039e-01,  9.60477829e-01,  9.49231923e-01,\n",
              "         -6.83828115e-01, -7.17898786e-01,  2.86706716e-01,\n",
              "         -7.60040998e-01,  4.78332311e-01, -9.51963365e-01,\n",
              "          8.08321238e-01,  5.27614176e-01, -1.67665794e-01,\n",
              "          9.16268051e-01, -8.87899160e-01, -5.93430936e-01,\n",
              "          3.90307993e-01, -7.76923180e-01, -3.84818405e-01,\n",
              "          9.59038138e-01,  6.78381324e-01, -4.08702850e-01,\n",
              "         -1.99678838e-02, -4.68428612e-01, -7.41143048e-01,\n",
              "         -9.73734498e-01,  6.23253822e-01,  1.00000000e+00,\n",
              "         -4.31855321e-01,  8.94348621e-01, -5.72569311e-01,\n",
              "         -1.89501494e-02,  7.24834427e-02,  6.05421424e-01,\n",
              "          5.64564109e-01, -5.04034936e-01, -8.33653271e-01,\n",
              "          9.20378506e-01, -9.70664740e-01, -9.92627323e-01,\n",
              "          8.63119483e-01,  2.32818350e-01, -3.05338472e-01,\n",
              "          9.99999225e-01,  6.51024401e-01,  3.69558811e-01,\n",
              "          5.16951740e-01,  9.89937425e-01, -5.10574952e-02,\n",
              "          5.19780934e-01,  9.13519502e-01,  9.89344239e-01,\n",
              "         -4.06514168e-01,  6.72227502e-01,  8.66246164e-01,\n",
              "         -9.63320732e-01, -3.93905461e-01, -7.32534230e-01,\n",
              "          6.66500926e-02, -9.50429082e-01,  5.36764041e-02,\n",
              "         -9.64523733e-01,  9.78591144e-01,  9.72525120e-01,\n",
              "          5.02412915e-01,  3.42612803e-01,  8.20066929e-01,\n",
              "          1.00000000e+00, -8.37067425e-01,  5.97411513e-01,\n",
              "         -4.17202145e-01,  8.81286144e-01, -9.99911070e-01,\n",
              "         -8.37778091e-01, -4.66962218e-01, -2.72496670e-01,\n",
              "         -9.03814375e-01, -4.58637834e-01,  3.91833514e-01,\n",
              "         -9.79059279e-01,  9.10196245e-01,  8.29555333e-01,\n",
              "         -9.92893696e-01, -9.93933380e-01, -5.58821321e-01,\n",
              "          7.86012173e-01,  2.98600942e-01, -9.94314432e-01,\n",
              "         -8.16725373e-01, -6.58431947e-01,  9.07821834e-01,\n",
              "         -4.84595984e-01, -9.59578753e-01, -5.24700582e-01,\n",
              "         -4.26523238e-01,  5.39447427e-01, -3.51429611e-01,\n",
              "          6.03987813e-01,  8.84236515e-01,  6.91960335e-01,\n",
              "         -7.73553550e-01, -3.49986702e-01, -1.82106078e-01,\n",
              "         -8.09592664e-01,  9.06841457e-01, -8.09706330e-01,\n",
              "         -9.76247668e-01, -2.70705551e-01,  1.00000000e+00,\n",
              "         -5.54332674e-01,  8.93760264e-01,  7.55229771e-01,\n",
              "          7.80316293e-01, -1.99225456e-01,  3.35151136e-01,\n",
              "          9.55944002e-01,  3.82269740e-01, -7.57196605e-01,\n",
              "         -9.39319909e-01, -6.35581732e-01, -6.07329130e-01,\n",
              "          7.00571895e-01,  7.23613024e-01,  7.29010999e-01,\n",
              "          8.65883648e-01,  7.64537394e-01,  2.08821043e-01,\n",
              "         -6.98528215e-02, -5.64204820e-04,  9.99799311e-01,\n",
              "         -4.44100142e-01, -1.80671513e-01, -4.89859760e-01,\n",
              "         -2.91431338e-01, -4.25409198e-01, -1.98749930e-01,\n",
              "          1.00000000e+00,  3.56602132e-01,  7.75661409e-01,\n",
              "         -9.93823767e-01, -9.28070962e-01, -9.31738615e-01,\n",
              "          1.00000000e+00,  8.50040436e-01, -7.60715961e-01,\n",
              "          7.18036532e-01,  7.75468946e-01, -1.75161943e-01,\n",
              "          8.09469342e-01, -3.36547762e-01, -3.02385300e-01,\n",
              "          4.57467943e-01,  3.08043808e-01,  9.70232069e-01,\n",
              "         -6.18903935e-01, -9.75721240e-01, -5.94948947e-01,\n",
              "          5.63390851e-01, -9.66651082e-01,  9.99981284e-01,\n",
              "         -6.10340416e-01, -3.60575050e-01, -4.96435881e-01,\n",
              "         -4.91436243e-01,  4.47817922e-01,  2.87387799e-02,\n",
              "         -9.83154833e-01, -3.47387314e-01,  3.09110701e-01,\n",
              "          9.66638982e-01,  3.75864029e-01, -6.41106427e-01,\n",
              "         -8.90264869e-01,  8.92269194e-01,  8.31999958e-01,\n",
              "         -9.59132016e-01, -9.57766473e-01,  9.71166372e-01,\n",
              "         -9.84971106e-01,  7.67819285e-01,  1.00000000e+00,\n",
              "          3.83998811e-01,  4.38051105e-01,  3.52292418e-01,\n",
              "         -4.46136504e-01,  4.46569294e-01, -6.90631270e-01,\n",
              "          6.74425602e-01, -9.59155858e-01, -4.53285038e-01,\n",
              "         -2.96152771e-01,  3.57684553e-01, -2.41154656e-01,\n",
              "         -5.88313341e-01,  7.63308346e-01,  3.13667417e-01,\n",
              "         -6.03100538e-01, -6.84795558e-01, -2.60147274e-01,\n",
              "          5.75160265e-01,  9.16844189e-01, -3.56800288e-01,\n",
              "         -2.31557801e-01,  1.15727842e-01, -1.77119061e-01,\n",
              "         -9.47563589e-01, -5.23141980e-01, -6.04617715e-01,\n",
              "         -9.99998629e-01,  5.41667879e-01, -1.00000000e+00,\n",
              "          6.60001993e-01,  3.39036584e-01, -2.57962257e-01,\n",
              "          8.98434043e-01,  3.58503759e-01,  7.80091882e-01,\n",
              "         -8.63456190e-01, -9.04243648e-01,  2.35174000e-01,\n",
              "          8.47542286e-01, -4.83704925e-01, -7.76437223e-01,\n",
              "         -7.77086914e-01,  4.51546967e-01, -1.20644100e-01,\n",
              "          3.45337898e-01, -7.58304536e-01,  7.38663554e-01,\n",
              "         -2.54878372e-01,  1.00000000e+00,  1.56726703e-01,\n",
              "         -6.47172868e-01, -9.80846465e-01,  3.21544856e-01,\n",
              "         -3.49479973e-01,  1.00000000e+00, -8.88086259e-01,\n",
              "         -9.70758736e-01,  4.17613953e-01, -6.59506500e-01,\n",
              "         -8.39061737e-01,  4.56445932e-01,  7.08390847e-02,\n",
              "         -8.59648764e-01, -9.68725741e-01,  9.56583977e-01,\n",
              "          8.95311117e-01, -6.79162502e-01,  7.91996121e-01,\n",
              "         -3.77204925e-01, -5.99682510e-01,  1.89219326e-01,\n",
              "          9.34770346e-01,  9.87944543e-01,  7.07964957e-01,\n",
              "          9.21087801e-01, -1.59540161e-01, -4.83467579e-01,\n",
              "          9.76640403e-01,  2.95252144e-01,  5.32053530e-01,\n",
              "          3.22658062e-01,  1.00000000e+00,  4.97991681e-01,\n",
              "         -9.31000829e-01, -3.24744463e-01, -9.82841671e-01,\n",
              "         -2.67996281e-01, -9.52166140e-01,  4.53916758e-01,\n",
              "          3.94372314e-01,  9.26190257e-01, -3.09752226e-01,\n",
              "          9.69366431e-01, -9.40263689e-01,  1.66798547e-01,\n",
              "         -8.32233071e-01, -7.04410970e-01,  5.49370348e-01,\n",
              "         -9.30373430e-01, -9.88702416e-01, -9.91572320e-01,\n",
              "          7.38682747e-01, -5.26327252e-01, -9.29532945e-02,\n",
              "          2.77956039e-01,  2.54385740e-01,  5.55893004e-01,\n",
              "          5.70780456e-01, -1.00000000e+00,  9.51999605e-01,\n",
              "          5.82980931e-01,  9.13393974e-01,  9.78624344e-01,\n",
              "          7.49032140e-01,  7.39971757e-01,  3.71186435e-01,\n",
              "         -9.89660740e-01, -9.84848499e-01, -5.31397939e-01,\n",
              "         -3.88979465e-01,  8.49413812e-01,  8.17017078e-01,\n",
              "          8.92696917e-01,  6.16892219e-01, -5.75284481e-01,\n",
              "         -2.86467344e-01, -7.60570526e-01, -7.78939366e-01,\n",
              "         -9.94441748e-01,  5.72188199e-01, -7.72194862e-01,\n",
              "         -9.57696259e-01,  9.67420697e-01, -2.17978761e-01,\n",
              "         -1.75552875e-01, -3.26556951e-01, -9.06777859e-01,\n",
              "          9.35597599e-01,  7.66239643e-01,  1.90596417e-01,\n",
              "          1.53928921e-01,  5.40217578e-01,  9.02483582e-01,\n",
              "          9.40388978e-01,  9.88884866e-01, -9.10143912e-01,\n",
              "          7.88360000e-01, -8.31382871e-01,  6.11195385e-01,\n",
              "          8.21668983e-01, -9.41967785e-01,  3.75133187e-01,\n",
              "          5.49405754e-01, -6.15318477e-01,  3.91501933e-01,\n",
              "         -3.66627157e-01, -9.74752426e-01,  8.88878047e-01,\n",
              "         -3.62838179e-01,  6.53205752e-01, -5.35069942e-01,\n",
              "         -2.21282095e-02, -4.40158129e-01, -3.87567252e-01,\n",
              "         -7.89354861e-01, -6.70902491e-01,  6.87369883e-01,\n",
              "          4.34680045e-01,  9.07510877e-01,  9.13954020e-01,\n",
              "         -1.07544973e-01, -8.54991853e-01, -3.22965890e-01,\n",
              "         -7.80992746e-01, -9.35075462e-01,  9.56621110e-01,\n",
              "         -2.46967360e-01, -1.84675947e-01,  7.18141854e-01,\n",
              "          1.66834027e-01,  9.54272509e-01,  5.20279408e-01,\n",
              "         -5.11346579e-01, -3.58430564e-01, -7.76734650e-01,\n",
              "          9.01378930e-01, -6.45810127e-01, -6.68203235e-01,\n",
              "         -6.79575741e-01,  8.30889344e-01,  4.56940055e-01,\n",
              "          9.99998212e-01, -8.61587286e-01, -9.52708542e-01,\n",
              "         -5.74054778e-01, -4.75623518e-01,  5.11585891e-01,\n",
              "         -7.02607334e-01, -1.00000000e+00,  5.05624473e-01,\n",
              "         -6.52045906e-01,  8.13730657e-01, -8.72139156e-01,\n",
              "          8.09319735e-01, -8.18221927e-01, -9.88196373e-01,\n",
              "         -4.00082380e-01,  3.38945836e-01,  7.67013729e-01,\n",
              "         -5.16352892e-01, -8.75940859e-01,  6.15952134e-01,\n",
              "         -7.52709627e-01,  9.89328444e-01,  8.95710766e-01,\n",
              "         -6.14250124e-01,  2.19650030e-01,  7.52754271e-01,\n",
              "         -8.20389748e-01, -8.05691302e-01,  9.38039422e-01]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 6, 768), dtype=float32, numpy=\n",
              " array([[[-0.07947472,  0.00580762, -0.31414002, ..., -0.4509729 ,\n",
              "           0.29333174,  0.23387676],\n",
              "         [ 0.39315987,  0.5033629 ,  0.24021392, ..., -0.32635602,\n",
              "           0.3498608 ,  0.20673233],\n",
              "         [ 0.35789236,  0.10767157, -0.04988848, ..., -0.50822747,\n",
              "           0.2504879 , -0.26268777],\n",
              "         [-0.29892233, -0.24708791,  0.0715151 , ..., -0.33810017,\n",
              "           0.12699501, -0.09681887],\n",
              "         [-0.36815387, -0.7146524 , -0.21032578, ...,  0.35395133,\n",
              "           0.33438605, -0.6233473 ],\n",
              "         [ 0.88692236, -0.1699696 , -0.2917365 , ...,  0.05816516,\n",
              "          -0.5775993 , -0.32075307]]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DCNNBERTEmbedding(tf.keras.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "                 nb_filters = 50,\n",
        "                 # number of hidden units\n",
        "                 FFN_units = 512,\n",
        "                 nb_classes = 2,\n",
        "                 dropout_rate = 0.1,\n",
        "                 training = False,\n",
        "                 name = \"dcnn\"):\n",
        "        super(DCNNBERTEmbedding, self).__init__(name = name)\n",
        "\n",
        "        # embedding layer made by BERT import form the website\n",
        "        # Embedding : vectorize words to map them into semantic geometric space\n",
        "        self.bert_layer = hub.KerasLayer(\n",
        "            \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "            trainable = False\n",
        "        )\n",
        "\n",
        "        # focus on 2 consecutive words\n",
        "        # Conv1D : shift feature detectors in only one dimension, Extract regional features using filters\n",
        "        self.bigram = layers.Conv1D(filters = nb_filters,\n",
        "                                    kernel_size = 2,\n",
        "                                    padding = \"valid\",\n",
        "                                    activation = \"relu\")\n",
        "        self.trigram = layers.Conv1D(filters = nb_filters,\n",
        "                                    kernel_size = 3,\n",
        "                                    padding = \"valid\",\n",
        "                                    activation = \"relu\")\n",
        "        self.fourgram = layers.Conv1D(filters = nb_filters,\n",
        "                                    kernel_size = 4,\n",
        "                                    padding = \"valid\",\n",
        "                                    activation = \"relu\")\n",
        "        # GlobalMaxPooling1D : Choose and return the largest vector of multiple vector information\n",
        "        self.pool = layers.GlobalMaxPooling1D()\n",
        "        self.dense_1 = layers.Dense(units = FFN_units, activation = \"relu\")\n",
        "        # need dropout layer to prevent overfitting\n",
        "        self.dropout = layers.Dropout(rate = dropout_rate)\n",
        "\n",
        "        if nb_classes == 2:\n",
        "            # units : Number of neurons active in that hidden layer\n",
        "            # activation : Which function will fit the calculation result of the weight and bias of the hidden layer and print it?\n",
        "            # 1 unit -> activation signoid (classification between 0 and 1)\n",
        "            self.last_dense = layers.Dense(units = 1, activation = \"sigmoid\")\n",
        "        else:\n",
        "            # nb_classes unit -> activation softmax\n",
        "            self.last_dense = layers.Dense(units = nb_classes,\n",
        "                                           activation = \"softmax\")\n",
        "\n",
        "    # embedder using bert\n",
        "    def embed_with_bert(self, all_tokens):\n",
        "        # input contains of three different types of tokens -> need to access them using all the batches\n",
        "        # tokens : cls, sep, pad\n",
        "        _, embs = self.bert_layer([all_tokens[:, 0, :],\n",
        "                                   all_tokens[:, 1, :],\n",
        "                                   all_tokens[:, 2, :]])\n",
        "        return embs\n",
        "\n",
        "    # if the training is false -> apply dropout\n",
        "    # while training -> dropout : in order to prevent overfitting\n",
        "    # while pedicting -> no dropout : in order to see all the results      \n",
        "    def call(self, inputs, training):\n",
        "        # embedding layer made by BERT\n",
        "        x = self.embed_with_bert(inputs)\n",
        "\n",
        "        # first set of output from the first se of Convolutional Layer\n",
        "        x_1 = self.bigram(x)\n",
        "        # apply the absolute maximum\n",
        "        # each of the 50 feature detectors of size 2 -> get 1 number which is maximum activation for the particular feature\n",
        "        x_1 = self.pool(x_1)\n",
        "        x_2 = self.trigram(x)\n",
        "        x_2 = self.pool(x_2)\n",
        "        x_3 = self.fourgram(x)\n",
        "        x_3 = self.pool(x_3)\n",
        "\n",
        "        # concat all the result and apply to the dense layer\n",
        "        # concat : Concatenates the list of tensors values along dimension axis\n",
        "        # x_1, x_2, x_3 shape : (batch_size, nb_filters) ---- concat ----> merged shape : (batch_size, 3 * nb_filters)\n",
        "        # axis = -1 : Concat based on the lowest dimension\n",
        "        merged = tf.concat([x_1, x_2, x_3], axis = -1)\n",
        "        merged = self.dense_1(merged)\n",
        "        # apply dropout\n",
        "        merged = self.dropout(merged, training)\n",
        "        # call output\n",
        "        output = self.last_dense(merged)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "0NomVTuE_CfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 4 : Training**"
      ],
      "metadata": {
        "id": "wXHwK3ERCOdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NB_FILTERS = 100\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NB_EPOCHS = 5"
      ],
      "metadata": {
        "id": "MVQjaj4aCRfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dcnn = DCNNBERTEmbedding(\n",
        "            nb_filters = NB_FILTERS,\n",
        "            FFN_units = FFN_UNITS,\n",
        "            nb_classes = NB_CLASSES,\n",
        "            dropout_rate = DROPOUT_RATE)"
      ],
      "metadata": {
        "id": "2eTOVzSnCid8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if NB_CLASSES == 2:\n",
        "    Dcnn.compile(loss = \"binary_crossentropy\",\n",
        "                 optimizer = \"adam\",\n",
        "                 metrics = [\"accuracy\"])\n",
        "else:\n",
        "    Dcnn.compile(loss = \"sparse_categorical_crossentropy\",\n",
        "                 optimizer = \"adam\",\n",
        "                 metrics = [\"sparse_categorical_accuracy\"])"
      ],
      "metadata": {
        "id": "949YIwZLErye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/Colab Notebooks/bert/ckpt_bert_embedding\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(Dcnn = Dcnn)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep = 1)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!\")"
      ],
      "metadata": {
        "id": "o8eEJWe_Fgn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa252be8-7e6d-4d75-9b54-5c5c1e220143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest checkpoint restored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs = None):\n",
        "        ckpt_manager.save()\n",
        "        print(\"Checkpoint saved as{}.\" .format(checkpoint_path))"
      ],
      "metadata": {
        "id": "zeOWRkszGgeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result**"
      ],
      "metadata": {
        "id": "20v6olDAG2bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dcnn.fit(train_dataset,\n",
        "         epochs = NB_EPOCHS,\n",
        "         callbacks = [MyCustomCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTQK4yusG31w",
        "outputId": "26bf7782-e990-47d4-f862-560566787fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "   4513/Unknown - 137s 27ms/step - loss: 0.2543 - accuracy: 0.8922Checkpoint saved as/content/drive/MyDrive/Colab Notebooks/bert/ckpt_bert_embedding.\n",
            "4513/4513 [==============================] - 139s 27ms/step - loss: 0.2543 - accuracy: 0.8922\n",
            "Epoch 2/5\n",
            "4513/4513 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.9073Checkpoint saved as/content/drive/MyDrive/Colab Notebooks/bert/ckpt_bert_embedding.\n",
            "4513/4513 [==============================] - 127s 28ms/step - loss: 0.2189 - accuracy: 0.9073\n",
            "Epoch 3/5\n",
            "4512/4513 [============================>.] - ETA: 0s - loss: 0.1883 - accuracy: 0.9201Checkpoint saved as/content/drive/MyDrive/Colab Notebooks/bert/ckpt_bert_embedding.\n",
            "4513/4513 [==============================] - 127s 28ms/step - loss: 0.1883 - accuracy: 0.9201\n",
            "Epoch 4/5\n",
            "4513/4513 [==============================] - ETA: 0s - loss: 0.1660 - accuracy: 0.9288Checkpoint saved as/content/drive/MyDrive/Colab Notebooks/bert/ckpt_bert_embedding.\n",
            "4513/4513 [==============================] - 124s 27ms/step - loss: 0.1660 - accuracy: 0.9288\n",
            "Epoch 5/5\n",
            "4513/4513 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.9361Checkpoint saved as/content/drive/MyDrive/Colab Notebooks/bert/ckpt_bert_embedding.\n",
            "4513/4513 [==============================] - 130s 29ms/step - loss: 0.1493 - accuracy: 0.9361\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f33aeb79fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 5 : Evaluation**"
      ],
      "metadata": {
        "id": "G2WwnXMFHnzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = Dcnn.evaluate(test_dataset)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv4-w6PaHxwN",
        "outputId": "035f73c1-425f-4796-c26b-8f5005329b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4513/4513 [==============================] - 122s 27ms/step - loss: 0.1831 - accuracy: 0.9245\n",
            "[0.18308138847351074, 0.9245443940162659]\n"
          ]
        }
      ]
    }
  ]
}